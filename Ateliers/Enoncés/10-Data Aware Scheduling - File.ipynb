{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Airflow/blob/main/Ateliers/Enonc%C3%A9s/10-Data%20Aware%20Scheduling%20-%20File.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Data Aware Scheduling\u202f: Cr\u00e9ation et consommation d'un dataset pour le data-aware\n",
                "\n"
            ],
            "metadata": {
                "id": "B_a5FkgNS9Nu"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "![dataaware](https://user-images.githubusercontent.com/123757632/231875385-9cf19dc7-c1fc-4b6a-8076-ed5417389188.png)"
            ],
            "metadata": {
                "id": "3jdtoEggTTUY"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "D\u00e9finir deux DAG (Directed Acyclic Graphs) distincts, \"producer_aware\" et \"consumer_aware\" :  \n",
                "\n",
                "- Le premier DAG (\"producer_aware\") g\u00e9n\u00e8re un ensemble de donn\u00e9es \u00e0 intervalles r\u00e9guliers et stocke ces donn\u00e9es dans un fichier CSV situ\u00e9 dans \"/tmp/data.csv\".Il est compos\u00e9 de deux t\u00e2ches BashOperator : \n",
                "    - \"generate_dataset\" : G\u00e9n\u00e8re une ligne de donn\u00e9es dans le fichier \"/tmp/data.csv\".\n",
                "    - \"check_file_task\" : V\u00e9rifie que le fichier existe et affiche son contenu \u00e0 la console. \n",
                "      \n",
                "La t\u00e2che \"generate_dataset\" est ex\u00e9cut\u00e9e en premier, puis la t\u00e2che \"check_file_task\" est ex\u00e9cut\u00e9e.\n",
                "\n",
                "- Le deuxi\u00e8me DAG (\"consumer_aware\") surveille ce fichier CSV et ex\u00e9cute une t\u00e2che qui lit les donn\u00e9es de ce fichier lorsqu'il est mis \u00e0 jour. Contient qu'une seule t\u00e2che BashOperator : \"consume_dataset\" :     \n",
                "  -  Cette t\u00e2che lit les donn\u00e9es stock\u00e9es dans le fichier CSV \"/tmp/data.csv\" en ex\u00e9cutant la commande \"cat /tmp/data.csv\" dans un terminal. Cette t\u00e2che est configur\u00e9e pour \u00eatre ex\u00e9cut\u00e9e chaque fois que le fichier \"/tmp/data.csv\" est mis \u00e0 jour."
            ],
            "metadata": {
                "id": "00NJ-m6RVQ27"
            }
        }
    ]
}