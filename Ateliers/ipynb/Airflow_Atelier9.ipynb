{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Database Integration : Utilisation de PostgresHook pour exploiter les connexions et exécuter des requêtes "
      ],
      "metadata": {
        "id": "o06SipZRMQx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![postgres_hook](https://user-images.githubusercontent.com/123757632/231869429-b98fcf0a-4249-4a02-9a52-c48e7ba1c85a.png)\n",
        "\n",
        "Définir un DAG (Directed Acyclic Graph) Airflow qui sera planifiée pour s'exécuter quotidiennement à partir d'une date précise . Le DAG comprendra une fonctions \"run_query\":\n",
        "\n",
        "- La fonction run_query() exécute une requête SQL pour récupérer tous les enregistrements de la table **my_test_table** à partir d'une base de données PostgreSQL. Elle utilise la bibliothèque **PostgresHook** pour créer une connexion à la base de données et appelle la méthode **get_records(query)** pour exécuter la requête SQL. Enfin, elle itère sur les lignes retournées et les affiche à l'aide de la fonction print().\n",
        "\n",
        "Crée un opérateur Python appelé task qui exécutera la fonction run_query() lorsqu'il sera appelé dans le DAG. \n"
      ],
      "metadata": {
        "id": "3jdv7YybMdIY"
      }
    }
  ]
}