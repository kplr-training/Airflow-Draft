{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Airflow/blob/main/Ateliers/Enonces/04-Pipeline%20-%20Postgres.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construction d'une pipeline d'ex\u00e9cution avec PostgreSQL "
            ],
            "metadata": {
                "id": "o6lFtokOMzYI"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "![atelier4](https://user-images.githubusercontent.com/123757632/231912146-232774b4-c30c-4901-b4c1-ea27db59122b.png)"
            ],
            "metadata": {
                "id": "-AZaLXvTMtjM"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### T\u00e2ches de cr\u00e9ation de table\n",
                "\n",
                "Il est possible d'utiliser PostgresOperator afin de d\u00e9finir des t\u00e2ches qui cr\u00e9eront des tables dans la base de donn\u00e9es postgres.\n",
                "\n",
                "Il est pr\u00e9vu de cr\u00e9er deux tables : une pour faciliter le nettoyage des donn\u00e9es (employees_temp) et une autre pour stocker les donn\u00e9es nettoy\u00e9es (employees).\n",
                "\n",
                "* T\u00e2che 1 :  \n",
                "  - T\u00e2che nomm\u00e9e \"create_employees_table\". \n",
                "  - Cette t\u00e2che est associ\u00e9e \u00e0 une instance de PostgreSQL. \n",
                "  - La t\u00e2che ex\u00e9cute la commande SQL pour cr\u00e9er une table nomm\u00e9e \"employees\"  si elle n'existe pas avec des colonnes : \n",
                "      * \"Serial Number\" NUMERIC PRIMARY KEY,\n",
                "      * \"Company Name\" TEXT,\n",
                "      * \"Employee Markme\" TEXT,\n",
                "      * \"Description\" TEXT,\n",
                "      * \"Leave\" INTEGER\n",
                "\n",
                "* T\u00e2che 2 : \n",
                "  - T\u00e2che nomm\u00e9e \"create_employees_temp_table\".\n",
                "  - Cette t\u00e2che est associ\u00e9e \u00e0 une instance de PostgreSQL. \n",
                "  - La t\u00e2che ex\u00e9cute une commande SQL pour supprimer une table nomm\u00e9e \"employees_temp\" si elle existe, puis cr\u00e9e une nouvelle table portant le m\u00eame nom avec des colonnes : \n",
                "      * \"Serial Number\" NUMERIC PRIMARY KEY,\n",
                "      * \"Company Name\" TEXT,\n",
                "      * \"Employee Markme\" TEXT,\n",
                "      * \"Description\" TEXT,\n",
                "      * \"Leave\" INTEGER"
            ],
            "metadata": {
                "id": "ERei4t-MM61x"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### T\u00e2che de r\u00e9cup\u00e9ration de donn\u00e9es"
            ],
            "metadata": {
                "id": "PcU7qOskM8MZ"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Les donn\u00e9es sont r\u00e9cup\u00e9r\u00e9es, enregistr\u00e9es dans un fichier sur l'instance Airflow, puis charg\u00e9es \u00e0 partir de ce fichier dans une table interm\u00e9diaire afin de pouvoir ex\u00e9cuter les \u00e9tapes de nettoyage des donn\u00e9es.\n",
                "\n"
            ],
            "metadata": {
                "id": "alKx9CwOM_yr"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "D\u00e9finir une fonction nomm\u00e9e **\"get_data()\"** qui est d\u00e9cor\u00e9e par **\"@task\"**, indiquant qu'il s'agit d'une t\u00e2che Airflow. \n",
                "\n",
                "* Cette t\u00e2che t\u00e9l\u00e9charge un fichier CSV \u00e0 partir de l'URL \"https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/tutorial/pipeline_example.csv\" , \n",
                "\n",
                "* Utilise la biblioth\u00e8que **\"requests\"** pour envoyer une requ\u00eate GET \u00e0 l'URL et r\u00e9cup\u00e9rer les donn\u00e9es. \n"
            ],
            "metadata": {
                "id": "-IbToaktNFl7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "url = \"https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/tutorial/pipeline_example.csv\""
            ],
            "metadata": {
                "id": "V0lUfDCpNGVl"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "* Les donn\u00e9es sont ensuite \u00e9crites dans un fichier situ\u00e9 dans le chemin \"data_path\", qui est d\u00e9fini pour \u00eatre \"/opt/airflow/dags/files/employees.csv\". Si le chemin n'existe pas, il est cr\u00e9\u00e9 .  "
            ],
            "metadata": {
                "id": "2InC0nsQNIkC"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "data_path = \"/opt/airflow/dags/files/employees.csv\"\n",
                "os.makedirs(os.path.dirname(data_path), exist_ok=True)"
            ],
            "metadata": {
                "id": "pSYiobEVNMof"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "\n",
                "* Ensuite, la t\u00e2che utilise la biblioth\u00e8que **\"psycopg2\"** pour se connecter \u00e0 la base de donn\u00e9es PostgreSQL avec l'identifiant de connexion. \n"
            ],
            "metadata": {
                "id": "b8TuLWQNNNHQ"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "postgres_hook = PostgresHook(postgres_conn_id=\"******\")\n",
                "conn = postgres_hook.get_conn()\n",
                "cur = conn.cursor()"
            ],
            "metadata": {
                "id": "wYBLqIL4NPjb"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "\n",
                "* Elle ins\u00e8re les donn\u00e9es du fichier CSV dans une table temporaire nomm\u00e9e **\"employees_temp\"** \u00e0 l'aide de la m\u00e9thode \"copy_expert\" qui permet de copier les donn\u00e9es du fichier dans la table.\n",
                "    \n",
                "                \n"
            ],
            "metadata": {
                "id": "n9Zw-kuZNR-Q"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "with open(data_path, \"r\") as file:\n",
                "        cur.copy_expert(\n",
                "            \"COPY employees_temp FROM STDIN WITH CSV HEADER DELIMITER AS ',' QUOTE '\\\"'\",\n",
                "            file,\n",
                "        )"
            ],
            "metadata": {
                "id": "jwfaRjrgNa66"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "* Enfin, la t\u00e2che confirme la transaction en appelant \"conn.commit()\"."
            ],
            "metadata": {
                "id": "UIWZc7C3NdXU"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### T\u00e2che de fusion de donn\u00e9es\n",
                "\n",
                "Des enregistrements compl\u00e8tement uniques sont s\u00e9lectionn\u00e9s \u00e0 partir des donn\u00e9es r\u00e9cup\u00e9r\u00e9es, puis il est v\u00e9rifi\u00e9 si des num\u00e9ros de s\u00e9rie d'employ\u00e9s sont d\u00e9j\u00e0 pr\u00e9sents dans la base de donn\u00e9es. Si tel est le cas, ces enregistrements sont mis \u00e0 jour avec les nouvelles donn\u00e9es."
            ],
            "metadata": {
                "id": "pRy-wQY5Ng7o"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "D\u00e9finir une fonction nomm\u00e9e \"merge_data()\" qui est d\u00e9cor\u00e9e par \"@task\", indiquant qu'il s'agit d'une t\u00e2che Airflow.\n",
                "\n",
                "* La t\u00e2che fusionne les donn\u00e9es d'une table temporaire appel\u00e9e **employees_temp** dans une table permanente appel\u00e9e **employees**. Pour ce faire, elle s\u00e9lectionne toutes les lignes distinctes de employees_temp et les ins\u00e8re dans employees, ou met \u00e0 jour les lignes existantes s'il y a un conflit sur la colonne \"Serial Number\".\n",
                "\n",
                "* La t\u00e2che est ex\u00e9cut\u00e9e \u00e0 l'aide d'un **PostgresHook**, qui se connecte \u00e0 une base de donn\u00e9es **PostgreSQL** et ex\u00e9cute des requ\u00eates SQL. \n",
                "\n",
                "* La requ\u00eate SQL utilis\u00e9e dans cette t\u00e2che est d\u00e9finie dans la variable de requ\u00eate et utilise la syntaxe INSERT INTO ... "
            ],
            "metadata": {
                "id": "NKiyOusfNim1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "query = \"\"\"\n",
                "        INSERT INTO employees\n",
                "        SELECT *\n",
                "        FROM (\n",
                "            SELECT DISTINCT *\n",
                "            FROM employees_temp\n",
                "        ) t\n",
                "        ON CONFLICT (\"Serial Number\") DO UPDATE\n",
                "        SET\n",
                "              \"Employee Markme\" = excluded.\"Employee Markme\",\n",
                "              \"Description\" = excluded.\"Description\",\n",
                "              \"Leave\" = excluded.\"Leave\";\n",
                "    \"\"\""
            ],
            "metadata": {
                "id": "Ea_Iwi5mNolQ"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "* ON CONFLICT de Postgres pour g\u00e9rer les conflits lors de l'insertion de donn\u00e9es dans la table employees.\n",
                "Si la t\u00e2che s'ex\u00e9cute avec succ\u00e8s, elle renvoie 0. Si une exception se produit, elle renvoie 1. (Utilisez Exception)"
            ],
            "metadata": {
                "id": "4ZGC-cKGNru8"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Finalisation du DAG"
            ],
            "metadata": {
                "id": "52vUt1ibNuFL"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "* Utiliser l'op\u00e9rateur **>>** pour d\u00e9finir les d\u00e9pendances entre les t\u00e2ches. Cela indique que les t\u00e2ches \u00e0 gauche de l'op\u00e9rateur doivent \u00eatre ex\u00e9cut\u00e9es avant la t\u00e2che \u00e0 droite de l'op\u00e9rateur.\n",
                "\n",
                "* Plus pr\u00e9cis\u00e9ment, la ligne de code \u00e9tablit les d\u00e9pendances suivantes :\n",
                "\n",
                "  * Les t\u00e2ches create_employees_table et create_employees_temp_table doivent \u00eatre ex\u00e9cut\u00e9es avant la t\u00e2che get_data().\n",
                "  * La t\u00e2che get_data() doit \u00eatre ex\u00e9cut\u00e9e avant la t\u00e2che merge_data()."
            ],
            "metadata": {
                "id": "vO-MfVWbNwQu"
            }
        }
    ]
}