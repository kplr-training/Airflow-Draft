{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Airflow/blob/main/Ateliers/Solutions/08-Database%20Integration%20-%20Hook.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Database Integration\u202f: DAGs pour \u00e9crire et lire des donn\u00e9es dans PostgreSQL sans utilisation des hooks "
            ],
            "metadata": {
                "id": "3UWdtGJDF3T7"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "![pgaware_no hooks](https://user-images.githubusercontent.com/123757632/231477957-4ca75320-1980-4ca1-bf44-452400f88e76.png)"
            ],
            "metadata": {
                "id": "EswEEvVMF8b2"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "1 . Cr\u00e9e une liste nomm\u00e9e \"pg_dataset\" contenant un seul \u00e9l\u00e9ment. Le Dataset repr\u00e9sente une table PostgreSQL nomm\u00e9e \"my_test_table\" "
            ],
            "metadata": {
                "id": "zMqlEr9SHihk"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import psycopg2\n",
                "from datetime import datetime\n",
                "from airflow import DAG, Dataset\n",
                "from airflow.operators.python_operator import PythonOperator\n",
                "\n",
                "pg_dataset=[Dataset(\"postgres://airflow:airflow@postgres:5432/airflow?table=my_test_table\")]"
            ],
            "metadata": {
                "id": "V_saQ90oHgNj"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "2 . D\u00e9finir Le DAG \"write_to_postgres_ux\" qui sera planifi\u00e9 pour commencer \u00e0 s'ex\u00e9cuter \u00e0 partir du 9 avril 2023 et s'ex\u00e9cutera quotidiennement."
            ],
            "metadata": {
                "id": "5YYAeEjqIIVu"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "R698jRXzFdtt"
            },
            "outputs": [],
            "source": [
                "with DAG(\n",
                "    'write_to_postgres_ux',\n",
                "    start_date=datetime(2023, 4, 9),\n",
                "    schedule_interval='@daily'\n",
                ")as dag:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "3 . Ensuite, une fonction nomm\u00e9e \"write_to_postgres\" est d\u00e9finie. Cette fonction se connecte \u00e0 la base de donn\u00e9es PostgreSQL en utilisant la biblioth\u00e8que psycopg2. La fonction \"write_to_postgres\" cr\u00e9e une table nomm\u00e9e \"my_test_table\" si elle n'existe pas d\u00e9j\u00e0, ins\u00e8re une ligne de donn\u00e9es dans cette table, puis ferme la connexion \u00e0 la base de donn\u00e9es."
            ],
            "metadata": {
                "id": "9vyEUUCrIti1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def write_to_postgres():\n",
                "    conn = psycopg2.connect(\n",
                "        host=\"postgres\",\n",
                "        database=\"airflow\",\n",
                "        user=\"airflow\",\n",
                "        password=\"airflow\"\n",
                "    )\n",
                "    cur = conn.cursor()\n",
                "    cur.execute(\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS my_test_table (\n",
                "            col1 TEXT,\n",
                "            col2 TEXT\n",
                "        )\n",
                "    \"\"\")\n",
                "    cur.execute(\"INSERT INTO my_test_table (col1, col2) VALUES ('value1', 'value2')\")\n",
                "    conn.commit()\n",
                "    cur.close()\n",
                "    conn.close()\n"
            ],
            "metadata": {
                "id": "2mz-Om6-Is-K"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "4 . Ensuite, une t\u00e2che nomm\u00e9e \"write_task\" est cr\u00e9\u00e9e en utilisant la classe PythonOperator . Cette t\u00e2che ex\u00e9cute la fonction \"write_to_postgres\" d\u00e9finie pr\u00e9c\u00e9demment."
            ],
            "metadata": {
                "id": "kqEGgA7NI3vj"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "write_task = PythonOperator(\n",
                "    task_id='write_task',\n",
                "    python_callable=write_to_postgres,\n",
                "    dag=dag\n",
                ")"
            ],
            "metadata": {
                "id": "b-gKioFmI9lM"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "5 . D\u00e9finir le deuxi\u00e8me DAG nomm\u00e9 \"read_from_postgres_ux\". Ce DAG est cr\u00e9\u00e9 de la m\u00eame mani\u00e8re que le premier DAG, \u00e0 l'aide de la classe DAG."
            ],
            "metadata": {
                "id": "61f8GYSeI_Ld"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "with DAG(\n",
                "    'read_from_postgres_ux',\n",
                "    start_date=datetime(2023, 1, 1),\n",
                "    schedule = pg_dataset\n",
                ") as dag:"
            ],
            "metadata": {
                "id": "Ku_gKao3JJtX"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "6 . Ensuite, une fonction nomm\u00e9e \"read_from_postgres\" est d\u00e9finie. Cette fonction se connecte \u00e0 la base de donn\u00e9es PostgreSQL, lit toutes les lignes de la table \"my_test_table\", et les imprime dans la sortie console."
            ],
            "metadata": {
                "id": "iVs6ARCoJOH5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def read_from_postgres():\n",
                "    conn = psycopg2.connect(\n",
                "        host=\"postgres\",\n",
                "        database=\"airflow\",\n",
                "        user=\"airflow\",\n",
                "        password=\"airflow\"\n",
                "    )\n",
                "    cur = conn.cursor"
            ],
            "metadata": {
                "id": "GxfEohPEJT0l"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "7 . Cr\u00e9e une instance de la classe PythonOperator qui repr\u00e9sente une t\u00e2che qui sera ex\u00e9cut\u00e9e dans le DAG \"read_from_postgres_ux\". La t\u00e2che est identifi\u00e9e par \"task_id='read_task'\".\n",
                "\n",
                "Le code ex\u00e9cut\u00e9 par la t\u00e2che est d\u00e9fini dans la fonction \"read_from_postgres\". Cette fonction est pass\u00e9e en tant que param\u00e8tre \"python_callable\" de PythonOperator, ce qui signifie qu'elle sera appel\u00e9e lorsque la t\u00e2che sera ex\u00e9cut\u00e9e."
            ],
            "metadata": {
                "id": "NFd3xov4JgM-"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "read_task = PythonOperator(\n",
                "        task_id='read_task',\n",
                "        python_callable=read_from_postgres,\n",
                "        dag=dag\n",
                "    )"
            ],
            "metadata": {
                "id": "w72UNwy5Ji7y"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Execution du Dag :\n",
                "\n",
                "- DAG 1 : 'write_to_postgres_ux'\n",
                "\n",
                "![image](https://user-images.githubusercontent.com/123757632/231867091-f994c5b1-d8c3-4383-97db-a9b9fb128d41.png)\n",
                "\n",
                "- DAG 2 : 'read_from_postgres_ux'\n",
                "\n",
                "![image](https://user-images.githubusercontent.com/123757632/231867299-bc820406-13bc-40a2-9851-118d34e4f586.png)"
            ],
            "metadata": {
                "id": "gdTuTYTUJ8zX"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Dataset : \n",
                "\n",
                "![image](https://user-images.githubusercontent.com/123757632/231873981-27af1782-dc8a-44ce-9509-54296052c2f2.png)"
            ],
            "metadata": {
                "id": "jMKI9ASYRpjO"
            }
        }
    ]
}