{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Database Integration : DAGs pour écrire et lire des données dans PostgreSQL sans utilisation des hooks "
      ],
      "metadata": {
        "id": "3UWdtGJDF3T7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pgaware_no hooks](https://user-images.githubusercontent.com/123757632/231477957-4ca75320-1980-4ca1-bf44-452400f88e76.png)"
      ],
      "metadata": {
        "id": "EswEEvVMF8b2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 . Crée une liste nommée \"pg_dataset\" contenant un seul élément. Le Dataset représente une table PostgreSQL nommée \"my_test_table\" "
      ],
      "metadata": {
        "id": "zMqlEr9SHihk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "from datetime import datetime\n",
        "from airflow import DAG, Dataset\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "pg_dataset=[Dataset(\"postgres://airflow:airflow@postgres:5432/airflow?table=my_test_table\")]"
      ],
      "metadata": {
        "id": "V_saQ90oHgNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 . Définir Le DAG \"write_to_postgres_ux\" qui sera planifié pour commencer à s'exécuter à partir du 9 avril 2023 et s'exécutera quotidiennement."
      ],
      "metadata": {
        "id": "5YYAeEjqIIVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R698jRXzFdtt"
      },
      "outputs": [],
      "source": [
        "with DAG(\n",
        "    'write_to_postgres_ux',\n",
        "    start_date=datetime(2023, 4, 9),\n",
        "    schedule_interval='@daily'\n",
        ")as dag:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 . Ensuite, une fonction nommée \"write_to_postgres\" est définie. Cette fonction se connecte à la base de données PostgreSQL en utilisant la bibliothèque psycopg2. La fonction \"write_to_postgres\" crée une table nommée \"my_test_table\" si elle n'existe pas déjà, insère une ligne de données dans cette table, puis ferme la connexion à la base de données."
      ],
      "metadata": {
        "id": "9vyEUUCrIti1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_postgres():\n",
        "    conn = psycopg2.connect(\n",
        "        host=\"postgres\",\n",
        "        database=\"airflow\",\n",
        "        user=\"airflow\",\n",
        "        password=\"airflow\"\n",
        "    )\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS my_test_table (\n",
        "            col1 TEXT,\n",
        "            col2 TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"INSERT INTO my_test_table (col1, col2) VALUES ('value1', 'value2')\")\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n"
      ],
      "metadata": {
        "id": "2mz-Om6-Is-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 . Ensuite, une tâche nommée \"write_task\" est créée en utilisant la classe PythonOperator . Cette tâche exécute la fonction \"write_to_postgres\" définie précédemment."
      ],
      "metadata": {
        "id": "kqEGgA7NI3vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write_task = PythonOperator(\n",
        "    task_id='write_task',\n",
        "    python_callable=write_to_postgres,\n",
        "    dag=dag\n",
        ")"
      ],
      "metadata": {
        "id": "b-gKioFmI9lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 . Définir le deuxième DAG nommé \"read_from_postgres_ux\". Ce DAG est créé de la même manière que le premier DAG, à l'aide de la classe DAG."
      ],
      "metadata": {
        "id": "61f8GYSeI_Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with DAG(\n",
        "    'read_from_postgres_ux',\n",
        "    start_date=datetime(2023, 1, 1),\n",
        "    schedule = pg_dataset\n",
        ") as dag:"
      ],
      "metadata": {
        "id": "Ku_gKao3JJtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 . Ensuite, une fonction nommée \"read_from_postgres\" est définie. Cette fonction se connecte à la base de données PostgreSQL, lit toutes les lignes de la table \"my_test_table\", et les imprime dans la sortie console."
      ],
      "metadata": {
        "id": "iVs6ARCoJOH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_from_postgres():\n",
        "    conn = psycopg2.connect(\n",
        "        host=\"postgres\",\n",
        "        database=\"airflow\",\n",
        "        user=\"airflow\",\n",
        "        password=\"airflow\"\n",
        "    )\n",
        "    cur = conn.cursor"
      ],
      "metadata": {
        "id": "GxfEohPEJT0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 . Crée une instance de la classe PythonOperator qui représente une tâche qui sera exécutée dans le DAG \"read_from_postgres_ux\". La tâche est identifiée par \"task_id='read_task'\".\n",
        "\n",
        "Le code exécuté par la tâche est défini dans la fonction \"read_from_postgres\". Cette fonction est passée en tant que paramètre \"python_callable\" de PythonOperator, ce qui signifie qu'elle sera appelée lorsque la tâche sera exécutée."
      ],
      "metadata": {
        "id": "NFd3xov4JgM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "read_task = PythonOperator(\n",
        "        task_id='read_task',\n",
        "        python_callable=read_from_postgres,\n",
        "        dag=dag\n",
        "    )"
      ],
      "metadata": {
        "id": "w72UNwy5Ji7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution du Dag :\n",
        "\n",
        "- DAG 1 : 'write_to_postgres_ux'\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/123757632/231867091-f994c5b1-d8c3-4383-97db-a9b9fb128d41.png)\n",
        "\n",
        "- DAG 2 : 'read_from_postgres_ux'\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/123757632/231867299-bc820406-13bc-40a2-9851-118d34e4f586.png)"
      ],
      "metadata": {
        "id": "gdTuTYTUJ8zX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : \n",
        "\n",
        "![image](https://user-images.githubusercontent.com/123757632/231873981-27af1782-dc8a-44ce-9509-54296052c2f2.png)"
      ],
      "metadata": {
        "id": "jMKI9ASYRpjO"
      }
    }
  ]
}